{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNhSR_9Hov8c"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# [1] Required package installation\n",
        "# ==========================================\n",
        "!pip install xgboost lightgbm catboost optuna\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import optuna\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Model libraries\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# [1] Data loading and preprocessing\n",
        "# ==========================================\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Load the harmonized dataset for baseline ensemble experiments.\n",
        "\n",
        "    The function first checks whether Dataset.csv already exists in the\n",
        "    current working directory. If not, and if the script is running in\n",
        "    Google Colab, it prompts the user to upload the file manually.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        import os\n",
        "        if not os.path.exists('Dataset.csv'):\n",
        "            print(\"=== [Google Colab] Please upload Dataset.csv ===\")\n",
        "            uploaded = files.upload()\n",
        "            filename = list(uploaded.keys())[0]\n",
        "            df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "        else:\n",
        "            df = pd.read_csv('Dataset.csv')\n",
        "    except:\n",
        "        df = pd.read_csv('Dataset.csv')\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# [Important preprocessing step]\n",
        "# Sanitize column names to avoid downstream LightGBM parsing issues\n",
        "df.columns = [re.sub(r'[^A-Za-z0-9_]+', '_', col) for col in df.columns]\n",
        "print(\"Cleaned columns:\", df.columns.tolist())"
      ],
      "metadata": {
        "id": "ylWYJf2xpAes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# [1-1] Basic preprocessing\n",
        "# ==========================================\n",
        "# Drop redundant identifier column if present\n",
        "# (Country_Name is redundant if Country_Code is already available)\n",
        "if 'Country_Name' in df.columns:\n",
        "    df = df.drop('Country_Name', axis=1)\n",
        "\n",
        "# Define column groups\n",
        "cat_cols = ['Country_Code', 'Continent']\n",
        "target_col = 'Maternal_Mortality_Ratio'\n",
        "feature_names = [c for c in df.columns if c not in ['Year', target_col]]\n",
        "\n",
        "# Handle missing values\n",
        "# - categorical variables: Unknown\n",
        "# - numerical variables: median imputation\n",
        "for col in cat_cols:\n",
        "    df[col] = df[col].fillna(\"Unknown\")\n",
        "\n",
        "num_cols = [c for c in df.columns if c not in cat_cols + ['Year', target_col]]\n",
        "for col in num_cols:\n",
        "    df[col] = df[col].fillna(df[col].median())"
      ],
      "metadata": {
        "id": "d562NXympCmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# [1-2] Label encoding for categorical identifiers\n",
        "# ==========================================\n",
        "df_encoded = df.copy()\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df_encoded[col] = le.fit_transform(df[col].astype(str))"
      ],
      "metadata": {
        "id": "Bwx-AIMJpEX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# [1-3] Temporal split design\n",
        "# ==========================================\n",
        "# Phase 1: hyperparameter optimization\n",
        "# Train: 2011-2014 / Validation: 2015\n",
        "train_opt = df_encoded[(df_encoded['Year'] >= 2011) & (df_encoded['Year'] <= 2014)]\n",
        "val_opt   = df_encoded[df_encoded['Year'] == 2015]\n",
        "\n",
        "# Phase 2: retraining after model selection\n",
        "# Train: 2011-2015\n",
        "train_retrain = df_encoded[(df_encoded['Year'] >= 2011) & (df_encoded['Year'] <= 2015)]\n",
        "\n",
        "# Phase 3: final held-out evaluation\n",
        "# Test: 2016\n",
        "test = df_encoded[df_encoded['Year'] == 2016]\n",
        "\n",
        "# Utility function to separate X and y\n",
        "def get_xy(data):\n",
        "    return data[feature_names], data[target_col]\n",
        "\n",
        "X_opt_t, y_opt_t = get_xy(train_opt)\n",
        "X_opt_v, y_opt_v = get_xy(val_opt)\n",
        "X_final_t, y_final_t = get_xy(train_retrain)\n",
        "X_test, y_test = get_xy(test)"
      ],
      "metadata": {
        "id": "oPd72SAhpFta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# [2] Unified ensemble training function\n",
        "# ==========================================\n",
        "def run_ensemble(model_name):\n",
        "    \"\"\"\n",
        "    Run a complete baseline experiment for a selected ensemble model.\n",
        "\n",
        "    Workflow:\n",
        "    1. Hyperparameter optimization on 2011-2014 / 2015 split\n",
        "    2. Retraining on the full pretest period (2011-2015)\n",
        "    3. Evaluation on the held-out year 2016\n",
        "    4. Extraction of model-based feature importance\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*10} Processing {model_name} {'='*10}\")\n",
        "\n",
        "    # --- Step 1: Optuna optimization ---\n",
        "    def objective(trial):\n",
        "        if model_name == 'XGBoost':\n",
        "            params = {\n",
        "                'objective': 'reg:absoluteerror',\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
        "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "                'n_jobs': -1,\n",
        "                'eval_metric': 'mae',\n",
        "                'early_stopping_rounds': 20\n",
        "            }\n",
        "            model = xgb.XGBRegressor(**params)\n",
        "            model.fit(X_opt_t, y_opt_t, eval_set=[(X_opt_v, y_opt_v)], verbose=False)\n",
        "\n",
        "        elif model_name == 'LightGBM':\n",
        "            params = {\n",
        "                'objective': 'regression_l1',\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "                'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
        "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "                'verbose': -1,\n",
        "                'n_jobs': -1\n",
        "            }\n",
        "            model = lgb.LGBMRegressor(**params)\n",
        "\n",
        "            # Use LightGBM callback-based early stopping\n",
        "            model.fit(\n",
        "                X_opt_t, y_opt_t,\n",
        "                eval_set=[(X_opt_v, y_opt_v)],\n",
        "                eval_metric='mae',\n",
        "                callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=False)]\n",
        "            )\n",
        "\n",
        "        elif model_name == 'CatBoost':\n",
        "            params = {\n",
        "                'loss_function': 'MAE',\n",
        "                'iterations': trial.suggest_int('iterations', 100, 500),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "                'depth': trial.suggest_int('depth', 4, 10),\n",
        "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
        "                'verbose': 0,\n",
        "                'thread_count': -1\n",
        "            }\n",
        "            model = CatBoostRegressor(**params)\n",
        "            cat_features_idx = [i for i, c in enumerate(feature_names) if c in cat_cols]\n",
        "            model.fit(\n",
        "                X_opt_t, y_opt_t,\n",
        "                eval_set=(X_opt_v, y_opt_v),\n",
        "                cat_features=cat_features_idx,\n",
        "                early_stopping_rounds=20,\n",
        "                verbose=0\n",
        "            )\n",
        "\n",
        "        preds = model.predict(X_opt_v)\n",
        "        return mean_absolute_error(y_opt_v, preds)\n",
        "\n",
        "    print(\">> [Step 1] Optimizing hyperparameters...\")\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=10)\n",
        "    best_params = study.best_trial.params\n",
        "    print(f\"   Best parameters: {best_params}\")\n",
        "\n",
        "    # --- Step 2: Retraining on 2011-2015 ---\n",
        "    print(\">> [Step 2] Retraining on the full pretest period (2011-2015)...\")\n",
        "\n",
        "    if model_name == 'XGBoost':\n",
        "        final_params = best_params.copy()\n",
        "        final_params.pop('eval_metric', None)\n",
        "        final_params.pop('early_stopping_rounds', None)\n",
        "        final_model = xgb.XGBRegressor(**final_params, n_jobs=-1, enable_categorical=True)\n",
        "\n",
        "    elif model_name == 'LightGBM':\n",
        "        final_model = lgb.LGBMRegressor(**best_params, n_jobs=-1, verbose=-1)\n",
        "\n",
        "    elif model_name == 'CatBoost':\n",
        "        final_model = CatBoostRegressor(**best_params, verbose=0, thread_count=-1)\n",
        "\n",
        "    # Fit on the full pretest period\n",
        "    if model_name == 'CatBoost':\n",
        "        cat_features_idx = [i for i, c in enumerate(feature_names) if c in cat_cols]\n",
        "        final_model.fit(X_final_t, y_final_t, cat_features=cat_features_idx, verbose=0)\n",
        "    else:\n",
        "        final_model.fit(X_final_t, y_final_t)\n",
        "\n",
        "    # --- Step 3: Evaluation on the held-out year 2016 ---\n",
        "    print(\">> [Step 3] Evaluating on the held-out test year (2016)...\")\n",
        "    preds = final_model.predict(X_test)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    r2 = r2_score(y_test, preds)\n",
        "\n",
        "    # --- Step 4: Extract feature importance ---\n",
        "    if model_name == 'CatBoost':\n",
        "        imp_vals = final_model.get_feature_importance()\n",
        "    elif model_name == 'LightGBM':\n",
        "        imp_vals = final_model.feature_importances_\n",
        "    else:  # XGBoost\n",
        "        imp_vals = final_model.feature_importances_\n",
        "\n",
        "    importances = pd.Series(imp_vals, index=feature_names).sort_values(ascending=False)\n",
        "\n",
        "    return {\n",
        "        'Metrics': {'MAE': mae, 'RMSE': rmse, 'R2': r2},\n",
        "        'Importance': importances,\n",
        "        'Preds': preds\n",
        "    }"
      ],
      "metadata": {
        "id": "7qg1l516pHnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# [3] Run all baseline models\n",
        "# ==========================================\n",
        "results = {}\n",
        "models_list = ['XGBoost', 'LightGBM', 'CatBoost']\n",
        "\n",
        "for m in models_list:\n",
        "    results[m] = run_ensemble(m)"
      ],
      "metadata": {
        "id": "6MIuwuRdpKgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# [4] Result comparison and visualization\n",
        "# ==========================================\n",
        "\n",
        "# 1. Summary performance table\n",
        "metrics_df = pd.DataFrame(\n",
        "    {m: results[m]['Metrics'] for m in models_list}\n",
        ").T[['MAE', 'RMSE', 'R2']]\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\" FINAL RESULTS (Held-out Test Year: 2016) \")\n",
        "print(\"=\"*40)\n",
        "print(metrics_df)\n",
        "\n",
        "# 2. Performance comparison plot\n",
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "metrics_df[['MAE', 'RMSE']].plot(\n",
        "    kind='bar',\n",
        "    ax=ax1,\n",
        "    width=0.4,\n",
        "    position=1,\n",
        "    color=['#74b9ff', '#a29bfe']\n",
        ")\n",
        "ax1.set_ylabel(\"Error (MAE / RMSE)\", fontsize=12)\n",
        "ax1.set_title(\"Ensemble Baseline Performance Comparison (Held-out Test Year: 2016)\", fontsize=14)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "metrics_df['R2'].plot(\n",
        "    kind='bar',\n",
        "    ax=ax2,\n",
        "    width=0.2,\n",
        "    position=0,\n",
        "    color='#ff7675',\n",
        "    label='R2 Score'\n",
        ")\n",
        "ax2.set_ylabel(\"R2 Score\", color='#ff7675', fontsize=12)\n",
        "ax2.set_ylim(0, 1.1)\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# 3. Feature importance comparison (Top 10)\n",
        "fig, axs = plt.subplots(1, 3, figsize=(20, 6))\n",
        "colors = ['#74b9ff', '#a29bfe', '#ff7675']\n",
        "\n",
        "for i, model in enumerate(models_list):\n",
        "    results[model]['Importance'].nlargest(10).sort_values().plot(\n",
        "        kind='barh',\n",
        "        ax=axs[i],\n",
        "        color=colors[i]\n",
        "    )\n",
        "    axs[i].set_title(f\"{model} Feature Importance\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4. Optional: prediction scatter plots\n",
        "plt.figure(figsize=(18, 5))\n",
        "for i, model in enumerate(models_list):\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    sns.scatterplot(\n",
        "        x=y_test,\n",
        "        y=results[model]['Preds'],\n",
        "        alpha=0.6,\n",
        "        color=colors[i]\n",
        "    )\n",
        "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "    plt.title(f\"{model} Predictions (R2: {results[model]['Metrics']['R2']:.3f})\")\n",
        "    plt.xlabel(\"Actual\")\n",
        "    plt.ylabel(\"Predicted\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k-b-w823pMEp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
